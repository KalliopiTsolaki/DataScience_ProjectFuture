{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1_Preprocessing.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMfTm1M4dIlMI3xHGdE1IFF"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"tCeHvISD_1yg","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import seaborn as sns\n","\n","from datetime import date\n","from sklearn.model_selection import train_test_split, RandomizedSearchCV\n","from sklearn import preprocessing\n","from sklearn.externals import joblib\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","import math\n","import re\n","import datetime\n","\n","from google.colab import drive"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_a8kUQEDAopZ","colab_type":"code","colab":{}},"source":["def add_col_brand(users):\n","  users['brand'] = devices['brand']\n","  mapping_dict_brand = {'Apple': 0, 'Android': 1, 'Unknown': float('NaN')}\n","  users['brand'] = users['brand'].map(mapping_dict_brand) \n","  return users\n","\n","def mapping_data(users):  \n","  mapping_dict_plan = {'STANDARD': 0, 'SILVER': 1, 'GOLD': 1}\n","  users['plan'] = users['plan'].map(mapping_dict_plan)\n","  return users\n","\n","def add_col_age(users):\n","  now = datetime.datetime.now()\n","  users['age'] = users['birth_year'].apply(lambda x: now.year - x)\n","  return users\n","\n","def user_id_to_int(df):\n","  df['user_id'] = df['user_id'].apply(lambda x: int(x.split(\"_\")[1]))\n","  return df\n","\n","def add_inbound_outbound(users,users_trans):\n","  inbound_list = [0] * users.shape[0]\n","  outbound_list = [0] * users.shape[0]\n","  inbound_outbound_ratio_list  = [0] * users.shape[0]\n","\n","  for idx_users_trans, users_trans_row in users_trans.iterrows():\n","    if users_trans_row['direction'] == 'INBOUND':\n","      inbound_list[users_trans_row['user_id']] = inbound_list[users_trans_row['user_id']] + 1\n","    elif users_trans_row['direction'] == 'OUTBOUND':\n","      outbound_list[users_trans_row['user_id']] = outbound_list[users_trans_row['user_id']] + 1\n","\n","  for i in range(len(users)):\n","    inbound_outbound_total = inbound_list[i] + outbound_list[i]\n","    if (inbound_outbound_total == 0):\n","      inbound_outbound_ratio_list[i] = 0\n","    else:  \n","      inbound_outbound_ratio_list[i] = inbound_list[i] / inbound_outbound_total\n","\n","  \n","  inbound_ser = pd.Series(inbound_list)\n","  outbound_ser = pd.Series(outbound_list)\n","  inbound_outbound_ratio_ser = pd.Series(inbound_outbound_ratio_list)\n","  users['inbound_transactions'] = inbound_ser\n","  users['outbound_transactions'] = outbound_ser\n","  users['inbound_outbound_ratio'] = inbound_outbound_ratio_ser\n","  return users\n","\n","def add_completed_to_failed_trans_ratio(users,users_trans):\n","  completed_list = [0] * users.shape[0]\n","  failed_list = [0] * users.shape[0]\n","  completed_failed_ratio_list  = [0] * users.shape[0]\n","\n","  for idx_users_trans, users_trans_row in users_trans.iterrows():\n","    if users_trans_row['transactions_state'] == 'COMPLETED':\n","      completed_list[users_trans_row['user_id']] = completed_list[users_trans_row['user_id']] + 1\n","    elif users_trans_row['transactions_state'] == 'FAILED':\n","      failed_list[users_trans_row['user_id']] = failed_list[users_trans_row['user_id']] + 1\n","\n","  for i in range(len(users)):\n","    completed_failed_total = completed_list[i] + failed_list[i]\n","    if (completed_failed_total == 0):\n","      completed_failed_ratio_list[i] = 0\n","    else:  \n","      completed_failed_ratio_list[i] = completed_list[i] / completed_failed_total\n","\n","  \n","  completed_ser = pd.Series(completed_list)\n","  failed_ser = pd.Series(failed_list)\n","  completed_failed_ratio_ser = pd.Series(completed_failed_ratio_list)\n","  users['completed_transactions'] = completed_ser\n","  users['failed_transactions'] = failed_ser\n","  users['completed_failed_ratio'] = completed_failed_ratio_ser\n","  return users\n","\n","def add_average_amount_per_transaction(users,users_trans):\n","  avg_amount_list = [0] * len(users)\n","  \n","  for idx_users_trans, users_trans_row in users_trans.iterrows():\n","    avg_amount_list[users_trans_row['user_id']] = avg_amount_list[users_trans_row['user_id']] + users_trans_row['amount_usd'] \n","\n","  for idx_user, users_row in users.iterrows():\n","    avg_amount_list[idx_user] = avg_amount_list[idx_user] / users_row['transactions_count']\n","      \n","  avg_amount_ser = pd.Series(avg_amount_list)\n","  users['average_amount_per_transaction'] = avg_amount_ser\n","  return users\n","\n","def add_abroad_to_non_abroad(users, users_trans):\n","  abroad_trans_list = []\n","  non_abroad_trans_list = []\n","  abr_to_non_abr_ratio = []\n","\n","  for i in range(len(users)):\n","    abroad_trans_list.append(0)\n","    non_abroad_trans_list.append(0)\n","    abr_to_non_abr_ratio.append(0)\n","\n","  for idx_users_trans, users_trans_row in users_trans.iterrows():\n","    if users_trans_row['country'] != users_trans_row['ea_merchant_country'] and users_trans_row['ea_merchant_country'] != float('NaN'):\n","      abroad_trans_list[users_trans_row['user_id']] = abroad_trans_list[users_trans_row['user_id']] + 1\n","    else:\n","      non_abroad_trans_list[users_trans_row['user_id']] = non_abroad_trans_list[users_trans_row['user_id']] + 1\n","\n","  for i in range(len(users)):\n","    abr_to_non_abr_ratio[i] = abroad_trans_list[i] / (abroad_trans_list[i] + non_abroad_trans_list[i])\n","\n","  abroad_trans_ser = pd.Series(abroad_trans_list)\n","  non_abroad_trans_ser = pd.Series(non_abroad_trans_list)\n","  abr_to_non_abr_ratio_ser = pd.Series(abr_to_non_abr_ratio)\n","\n","  users['abroad_transactions'] = abroad_trans_ser\n","  users['non_abroad_transactions'] = non_abroad_trans_ser\n","  users['abroad_to_non_abroad_ratio'] = abr_to_non_abr_ratio_ser\n","\n","  return users\n","\n","def add_cardholder_presence(users, users_trans):\n","  presence_list = []\n","  non_presence_list = []\n","  pres_to_non_pres_ratio = []\n","\n","  for i in range(len(users)):\n","    presence_list.append(0)\n","    non_presence_list.append(0)\n","    pres_to_non_pres_ratio.append(0)\n","\n","  for idx_users_trans, users_trans_row in users_trans.iterrows():\n","    if users_trans_row['ea_cardholderpresence'] == 'TRUE':\n","      presence_list[users_trans_row['user_id']] = presence_list[users_trans_row['user_id']] + 1\n","    elif users_trans_row['ea_cardholderpresence'] == 'FALSE':\n","      non_presence_list[users_trans_row['user_id']] = non_presence_list[users_trans_row['user_id']] + 1\n","\n","  for i in range(len(users)):\n","    total =  (presence_list[i] + non_presence_list[i])\n","    if(total!=0):\n","      pres_to_non_pres_ratio[i] = presence_list[i] / total\n","\n","  pres_to_non_pres_ratio_ser = pd.Series(pres_to_non_pres_ratio)\n","  users['presence_to_non_presence_ratio'] = pres_to_non_pres_ratio_ser\n","\n","  return users\n","\n","def add_largest_trans_amount(users, users_trans):\n","  largest_trans_list = []\n","\n","  for i in range(len(users)):\n","    largest_trans_list.append(0)\n","\n","  for idx_users_trans, users_trans_row in users_trans.iterrows():\n","    if(largest_trans_list[users_trans_row['user_id']] != float('NaN')):\n","      if users_trans_row['amount_usd'] > int(largest_trans_list[users_trans_row['user_id']]):\n","        largest_trans_list[users_trans_row['user_id']] = users_trans_row['amount_usd'] \n","\n","  largest_trans_ser = pd.Series(largest_trans_list)\n","  users['largest_transaction_amount'] = largest_trans_ser\n","\n","  return users  \n","\n","def add_months_subscribed(users):\n","  now = datetime.datetime.now()\n","  months_subscribed_list = [0] * users.shape[0]\n","\n","  for idx_users, users_row in users.iterrows():\n","    date_split = users_row['created_date'].split(\"-\")\n","    year_created = int(date_split[0])\n","    month_created = int(date_split[1])\n","    if now.year == year_created:\n","      total_months = now.month - month_created\n","    else:\n","      diff = now.year - year_created  \n","      total_months = now.month + ((diff * 12) - month_created)\n","    \n","    months_subscribed_list[idx_users] = total_months\n","\n","  months_subscribed_ser = pd.Series(months_subscribed_list)\n","  users['months_subscribed'] = months_subscribed_ser\n","\n","  return users\n","\n","def add_transaction_count(users,users_trans):\n","  trans_count_by_user = users_trans.groupby(['user_id']).count()\n","  users['transactions_count'] = trans_count_by_user.iloc[:,0] \n","  return users\n","\n","\n","def add_trans_total_amount(users,users_trans):\n","  trans_sum_by_user = users_trans.groupby(['user_id']).sum()\n","  users['transactions_total_amount'] = trans_sum_by_user['amount_usd'] \n","  return users\n","\n","\n","def convert_country_code(users, country_codes_file):\n","  dictionary = {}\n","  with open(country_codes_file) as f:\n","      for line in f:\n","        country, alpha2_code, alpha3_code, numeric = line.split('|')\n","        dictionary[alpha2_code] = alpha3_code\n","\n","  users['country'] = users['country'].map(dictionary)\n","  return users\n","\n","\n","def add_mcc(users, users_trans):\n","\n","  users_trans['ea_merchant_mcc'] = users_trans['ea_merchant_mcc'].fillna(0)\n","\n","  size = users.shape[0]\n","  all_mcc_lists = []\n","  all_mcc_count_lists = []\n","  mcc_categories = [(1, 1499), (1500, 2999), (3000, 3999), (4000, 4799), (4800, 4999), (5000, 5599), (5600, 5699), (5700, 7299), (7300, 7999), (8000, 8999), (9000, 9999)]\n","\n","  for list in range(len(mcc_categories)):\n","    mcc_list = [0] * size\n","    mcc_count = [0] * size\n","\n","    all_mcc_lists.append(mcc_list)\n","    all_mcc_count_lists.append(mcc_count)\n","\n","\n","  for idx_users_trans, users_trans_row in users_trans.iterrows():\n","    user_mcc = users_trans_row['ea_merchant_mcc']\n","    for index, category in enumerate(mcc_categories):\n","      if(user_mcc >= category[0] and user_mcc <= category[1]):\n","        all_mcc_lists[index][users_trans_row['user_id']] = all_mcc_lists[index][users_trans_row['user_id']] + users_trans_row['amount_usd']\n","        all_mcc_count_lists[index][users_trans_row['user_id']] = all_mcc_count_lists[index][users_trans_row['user_id']] + 1\n","\n","\n","  for idx_mcc_cat, mcc_category in enumerate(all_mcc_count_lists):\n","    for idx_mcc_user, mcc_user in enumerate(mcc_category):\n","      if(mcc_user != 0):\n","        all_mcc_lists[idx_mcc_cat][idx_mcc_user] = all_mcc_lists[idx_mcc_cat][idx_mcc_user] / mcc_user\n","      else: \n","        all_mcc_lists[idx_mcc_cat][idx_mcc_user] = 0\n","\n","  for mcc_category in range(len(all_mcc_lists)):\n","    users['mcc_'+str(mcc_category)] = pd.Series(all_mcc_lists[mcc_category])\n","\n","  \n","  return users\n","\n","\n","def cardholder_pres_fillna(presence):\n","  \n","  if presence == 'UNKNOWN':\n","    return 'FALSE'\n","  else:\n","    return presence\n","\n","\n","def cardholder_fillna(df):\n","  df['ea_cardholderpresence'] = df['ea_cardholderpresence'].fillna('UNKNOWN')\n","\n","  df['ea_cardholderpresence'] = df['ea_cardholderpresence'].apply(cardholder_pres_fillna)\n","  return df\n","\n","\n","def remove_outliers(series):\n","  x = series\n","  UPPERBOUND, LOWERBOUND = np.percentile(x, [1,99])\n","  y = np.clip(x, UPPERBOUND, LOWERBOUND)\n","  return pd.Series(y)\n","\n","\n","def normalize(series):\n","  scaler = preprocessing.MinMaxScaler()\n","  column_as_array = series.to_numpy().reshape(-1,1)\n","  scaled = scaler.fit_transform(column_as_array)\n","  scaled_df = pd.DataFrame(scaled)\n","\n","  joblib.dump(scaler, project_dir + 'auxiliary_data/scalers/MinMax_' + series.name + '.save')\n","\n","  return scaled_df[0]\n","\n","\n","def standardize(series):\n","  scaler = preprocessing.StandardScaler()\n","  column_as_array = series.to_numpy().reshape(-1,1)\n","  scaled = scaler.fit_transform(column_as_array)\n","  scaled_df = pd.DataFrame(scaled)\n","\n","  joblib.dump(scaler, project_dir + 'auxiliary_data/scalers/Stand_' + series.name + '.save')\n","\n","  return scaled_df[0]\n","\n","\n","def extract_trans_features(users, transactions):\n","\n","    user_trans = pd.merge(transactions, users,on='user_id',how='left')\n","\n","    inbound_per_user = pd.DataFrame(transactions[transactions['direction']== 'INBOUND'].groupby(['user_id'])['direction'].size().reset_index(name='inbound_transactions'))\n","    users = pd.merge(inbound_per_user, users, on='user_id', how='outer')\n","    \n","    outbound_per_user = pd.DataFrame(transactions[transactions['direction']== 'OUTBOUND'].groupby(['user_id'])['direction'].size().reset_index(name='outbound_transactions'))\n","    users = pd.merge(outbound_per_user, users, on='user_id', how='outer')\n","\n","\n","\n","    completed_per_user = pd.DataFrame(transactions[transactions['transactions_state']== 'COMPLETED'].groupby(['user_id'])['transactions_state'].size().reset_index(name='completed_transactions'))\n","    users = pd.merge(completed_per_user, users, on='user_id', how='outer')\n","\n","    declined_per_user = pd.DataFrame(transactions[transactions['transactions_state']== 'DECLINED'].groupby(['user_id'])['transactions_state'].size().reset_index(name='declined_transactions'))\n","    users = pd.merge(declined_per_user, users, on='user_id', how='outer')\n","\n","    reverted_per_user = pd.DataFrame(transactions[transactions['transactions_state']== 'REVERTED'].groupby(['user_id'])['transactions_state'].size().reset_index(name='reverted_transactions'))\n","    users = pd.merge(reverted_per_user, users, on='user_id', how='outer')\n","\n","    failed_per_user = pd.DataFrame(transactions[transactions['transactions_state']== 'FAILED'].groupby(['user_id'])['transactions_state'].size().reset_index(name='failed_transactions'))\n","    users = pd.merge(failed_per_user, users, on='user_id', how='outer')\n","\n","    pending_per_user = pd.DataFrame(transactions[transactions['transactions_state']== 'PENDING'].groupby(['user_id'])['transactions_state'].size().reset_index(name='pending_transactions'))\n","    users = pd.merge(pending_per_user, users, on='user_id', how='outer')\n","\n","    cancelled_per_user = pd.DataFrame(transactions[transactions['transactions_state']== 'CANCELLED'].groupby(['user_id'])['transactions_state'].size().reset_index(name='cancelled_transactions'))\n","    users = pd.merge(cancelled_per_user, users, on='user_id', how='outer')\n","\n","    #number of transactions per user\n","    trans_per_user = pd.DataFrame(transactions.groupby(['user_id'])['transactions_state'].size().reset_index(name='TransPerUser'))\n","\n","   \n","    users['inbound_outbound_ratio'] = users['inbound_transactions'] / (users['inbound_transactions'] + users['outbound_transactions'])\n","\n","    users['completed_transactions'] = users['completed_transactions'] / trans_per_user['TransPerUser']\n","    users['declined_transactions'] = users['declined_transactions'] / trans_per_user['TransPerUser']\n","    users['reverted_transactions'] = users['reverted_transactions'] / trans_per_user['TransPerUser']\n","    users['failed_transactions'] = users['failed_transactions'] / trans_per_user['TransPerUser']\n","    users['pending_transactions'] = users['pending_transactions'] / trans_per_user['TransPerUser']\n","    users['cancelled_transactions'] = users['cancelled_transactions'] / trans_per_user['TransPerUser']\n","    \n","    return users.fillna(0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HvZBllqyAsGP","colab_type":"code","colab":{}},"source":["def clean_string(astring):\n","    #convert to upper and replace empty space\n","    astring = astring.replace(\" \",\"\").upper()\n","    #remove numbers\n","    clean = ''.join([i for i in astring if not i.isdigit()])\n","    #remove special characters\n","    clean = re.sub(r\"^\\W+\", \"\", clean)\n","    #if empty rename to Other\n","    clean.strip()\n","    if len(clean) < 3 or clean == \"\" : clean = 'OTHER'\n","    #check for buchurest and prague\n","    if(clean == 'BUCURESTI' or clean == 'BUCUREȘTI'): clean = 'BUCHAREST'\n","    if(clean == 'PRAHA'): clean = 'PRAGUE'\n","    if(clean == 'WARSZAWA'): clean = 'WARSAW'\n","    if(clean == 'CO.DOUBLIN'): clean = 'DUBLIN'\n","    if(clean == 'LISBOA'): clean = 'LISBON'\n","    if(clean == 'MILANO'): clean = 'MILAN'\n","    if(clean == 'RĪGA'): clean = 'RIGA'\n","    if(clean == 'BRUXELLES'): clean = 'BRUSSELS'\n","    return clean\n","\n","\n","#Giorgos\n","#Map countries to other countries\n","c2c_dict = {'MQ' : 'FR','RE' : 'FR','GP' : 'FR','GI' : 'ES','GG' : 'GB','JE' : 'GB','IM' : 'IE'}            \n","def c2c(country):\n","    if country in c2c_dict.keys():\n","        return c2c_dict.get(country)\n","    return country\n","\n","\n","#Giorgos\n","#adjusted net annual income per capita\n","dict2018 = {'GB' : 35837, 'PL':12907,'FR':34837,'IE':43843,'RO':9561,'ES':25686,\n","            'LT':16125,'PT':18799,'MT': 17156 ,'DE':40265,'CH':65578,'CZ':17146,'IT':28806,\n","            'GR':17147,'CY':26328,'LV':13726,'NL' : 44668,'HU':12896,'BE':38814,'SE':46002,'BG':8073,\n","            'DK':51867,'NO':66019,'SI':20691,'AT':42074,'SK':15059,\n","            'HR':12586,'FI':41120,'EE':18993,'LU':60159,'IS' : 58011,'LI': 59872,'AU' : 43346}\n"," \n","#groups =  0-20k,20k-40k,40k-60k,above 60k\n"," \n","def group_countries(adict):\n","    for key,value in adict.items():\n","        if value < 20000:\n","            adict[key] =  1\n","        elif value >=20000 and value <40000:\n","            adict[key] = 2\n","        elif value < 60000 and  value >= 40000:\n","            adict[key] = 3\n","        else:\n","            adict[key] =4\n","    return adict\n","\n","\n","#Giorgos\n","#Map cities to 'IsCapital'\n","capitals = ['LONDON','WARSAW','PARIS','DUBLIN','BUCHAREST','MADRID','VILNIUS','LISBON',\n","           'VALLETTA','BERLIN','BERN','PRAGUE','MILAN','ATHENS','NICOSIA','RIGA','AMSTERDAM',\n","           'BUDAPEST','BRUSSELS','STOCKHOLM','SOFIA','COPENHAGEN','OSLO','LJUBLJANA','VIENNA',\n","            'BRATISLAVA','ZAGREB','HELSINSKI','TALLINN','LUXEMBOURG','STHELIER','GIBRALTAR']\n","def is_capital(city):\n","    if city in capitals:\n","        return 1\n","    return 0\n","\n","\n","def extract_nots_features(users, notifications):\n","    notifications = extract_date_features(notifications)\n","    notifications = pd.merge(notifications,users,on='user_id',how='left')\n","\n","\n","    #number of notifications per user\n","    nots_per_user = pd.DataFrame(notifications.groupby(['user_id'])['channel'].size().reset_index(name='NotsPerUser'))\n","    users = pd.merge(nots_per_user,users,on='user_id',how='outer')\n","    \n","    #number of emails per user\n","    emails_per_user = pd.DataFrame(notifications[notifications['channel']== 'EMAIL'].groupby(['user_id'])['channel'].size().reset_index(name='EmailsPerUser'))\n","    users = pd.merge(emails_per_user,users,on='user_id',how='outer')\n","\n","    \n","    #number of push per user\n","    push_per_user = pd.DataFrame(notifications[notifications['channel'] == 'PUSH'].groupby('user_id')['channel'].size().reset_index(name='PushPerUser'))\n","    users = pd.merge(push_per_user,users,on='user_id',how='outer')\n","    \n","    #number of SMS per user\n","    sms_per_user = pd.DataFrame(notifications[notifications['channel'] == 'SMS'].groupby('user_id')['channel'].size().reset_index(name='SmsPerUser'))\n","    users = pd.merge(sms_per_user,users,on='user_id',how='outer')\n","    \n","        \n","    users['AvgNotsPerMonth'] = users['NotsPerUser'] / users['months_subscribed']\n","    users['AvgEmailsPerMonth'] = users['EmailsPerUser'] / users['months_subscribed']\n","    users['AvgPushPerMonth'] = users['PushPerUser'] / users['months_subscribed']\n","    users['AvgSmsPerMonth'] = users['SmsPerUser'] / users['months_subscribed']\n","    \n","    return users.fillna(0)\n","\n","\n","def diff_month(d2):\n","    return (date(2019,5,20).year - d2.year) * 12 + date.today().month - d2.month\n","\n","\n","#Group notifications reasons to : \n","#1)Promotion - CustomerCentricity :\n","#PROMO,INVEST_IN_GOLD,PROMO_CARD_ORDER,BLACK_FRIDAY,BLUE_TUESDAY,\n","#SILVER_ENGAGEMENT_FEES_SAVED,METAL_RESERVE_PLAN,JOINING_ANNIVERSARY,ONBOARDING_TIPS_ACTIVATED_USERS,WELCOME_BACK\n","\n","#2)Services : REENGAGEMENT_ACTIVE_FUNDS,NO_INITIAL_CARD_ORDER,NO_INITIAL_CARD_USE,LOST_CARD_ORDER,\n","#MADE_MONEY_REQUEST_NOT_SPLIT_BILL,ENGAGEMENT_SPLIT_BILL_RESTAURANT,SILVER_ENGAGEMENT_INACTIVE_CARD,\n","\n","reasons_dict = {'PROMO':0,'INVEST_IN_GOLD':0,'PROMO_CARD_ORDER':0,'BLACK_FRIDAY':0,'BLUE_TUESDAY':0,\n","                'SILVER_ENGAGEMENT_FEES_SAVED':0,'METAL_RESERVE_PLAN':0,'JOINING_ANNIVERSARY':0,\n","                'ONBOARDING_TIPS_ACTIVATED_USERS':0,'WELCOME_BACK':0,'REENGAGEMENT_ACTIVE_FUNDS':1,'NO_INITIAL_CARD_ORDER':1,\n","                'NO_INITIAL_CARD_USE':1,'LOST_CARD_ORDER':1,'MADE_MONEY_REQUEST_NOT_SPLIT_BILL':1,\n","                'ENGAGEMENT_SPLIT_BILL_RESTAURANT':1,'SILVER_ENGAGEMENT_INACTIVE_CARD':1}\n","\n","def map_reasons(astring):\n","    if astring in reasons_dict.keys():\n","        return reasons_dict.get(astring)\n","    return -1\n","\n","\n","\n","def days_from_last_interaction(date):\n","    date = str(date)\n","    dt = datetime.datetime.strptime(date, '%Y-%m-%d %H:%M:%S.%f')\n","    delta =  datetime.datetime(2019,5,20) - dt\n","    return delta.days\n","\n","\n","#Giorgos\n","def epoch_of_year(month):\n","    if month in [12,1,2]:\n","        return 'Winter'\n","    elif month in [3,4,5]:\n","        return 'Spring'\n","    elif month in [6,7,8]:\n","        return 'Summer'\n","    else:\n","        return 'Autumn'\n","\n","#Giorgos\n","def half_of_month(day):\n","    if day <= 15 : return 1\n","    return 2\n","\n","\n","#Giorgos\n","def extract_date_features(dataframe):\n","    dataframe['created_date'] = [datetime.datetime.strptime(str(date_time_str), '%Y-%m-%d %H:%M:%S.%f') for date_time_str in dataframe['created_date']]\n","    dataframe['part_of_day'] = (dataframe['created_date'].dt.hour %24 + 4) //4\n","    '''dataframe['part_of_day'].replace({1: 'Late Night',\n","                      2: 'Early Morning',\n","                      3: 'Morning',\n","                      4: 'Noon',\n","                      5: 'Evening',\n","                      6: 'Night'},inplace=True)'''\n","    dataframe['part_of_week'] = dataframe['created_date'].dt.weekday\n","    '''dataframe['part_of_week'].replace({0:'Weekday',\n","                                      1:'Weekday',\n","                                      2:'Weekday',\n","                                      3:'Weekday',\n","                                      4:'Weekday',\n","                                      5:'Weekend',\n","                                      6:'Weekend'},inplace=True)'''\n","    dataframe['Half_of_month'] = dataframe['created_date'].dt.day.apply(half_of_month)\n","    dataframe['Month'] = dataframe['created_date'].dt.month\n","    dataframe['Epoch'] = dataframe['created_date'].dt.month.apply(epoch_of_year).map({'Winter':1,'Spring':2,'Summer':3,'Autumn':4})\n","    dataframe['Year'] = dataframe['created_date'].dt.year\n","\n","    return dataframe\n","\n","\n","def diff_year(year):\n","    return date(2019,5,20).year - year"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E0Ps3NntAvBp","colab_type":"code","outputId":"983c26d5-cfd3-42e0-b318-3e38c419bad5","executionInfo":{"status":"ok","timestamp":1591647406796,"user_tz":-180,"elapsed":13396,"user":{"displayName":"Popi Ts","photoUrl":"","userId":"05477953627549620209"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["drive.mount('/content/drive')\n","project_dir = '/content/drive/My Drive/Colab Notebooks/Data Science-Project Future/pf-ds-thes-team2/'\n","\n","devices_file = project_dir + 'data/devices.csv'\n","users_file = project_dir + 'data/users.csv'\n","trans1_file = project_dir + 'data/transactions_1.csv'\n","trans2_file = project_dir + 'data/transactions_2.csv'\n","trans3_file = project_dir + 'data/transactions_3.csv'\n","notif_file = project_dir + 'data/notifications.csv'\n","country_codes_file = project_dir + 'auxiliary_data/country_codes.csv'\n","\n","users = pd.read_csv(users_file)\n","devices = pd.read_csv(devices_file)\n","transactions_1 = pd.read_csv(trans1_file)\n","transactions_2 = pd.read_csv(trans2_file)\n","transactions_3 = pd.read_csv(trans3_file)\n","notifications = pd.read_csv(notif_file)\n","\n","all_transactions = [transactions_1, transactions_2, transactions_3]\n","transactions = pd.concat(all_transactions)\n","transactions = transactions.reset_index().drop(['index'], axis=1)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GjNyZgRfAzXw","colab_type":"code","colab":{}},"source":["#users = convert_country_code(users, country_codes_file)\n","users = user_id_to_int(users)\n","devices = user_id_to_int(devices)\n","transactions = user_id_to_int(transactions)\n","notifications = user_id_to_int(notifications)\n","transactions = cardholder_fillna(transactions)\n","\n","users_trans = users.merge(transactions, on='user_id', how='left')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O-mOp_d7A7S3","colab_type":"code","colab":{}},"source":["'''users = add_cardholder_presence(users, users_trans)\n","users = add_months_subscribed(users)\n","users = add_largest_trans_amount(users, users_trans)\n","users = add_cardholder_presence(users, users_trans)\n","#users = add_abroad_to_non_abroad(users, users_trans)\n","users = add_completed_to_failed_trans_ratio(users,users_trans)\n","users = add_transaction_count(users,users_trans)\n","users = add_average_amount_per_transaction(users,users_trans)\n","users = add_trans_total_amount(users,users_trans)\n","users = add_inbound_outbound(users,users_trans)\n","users = add_col_brand(users)\n","users = mapping_data(users) \n","users = add_col_age(users)\n","users = add_mcc(users,users_trans)'''\n","\n","users = add_months_subscribed(users)\n","users = mapping_data(users)\n","users = extract_trans_features(users, transactions)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SVN_3JyiA-88","colab_type":"code","colab":{}},"source":["users['city'] = users['city'].apply(clean_string)\n","users['city'] = users['city'].apply(is_capital)\n","\n","users['country'] = users['country'].apply(c2c)\n","users['country'] = users['country'].map(group_countries(dict2018))\n","\n","users['birth_year'] = [diff_year(year) for year in users['birth_year']]\n","users = users.rename(columns={\"birth_year\": \"Age\"})\n","\n","users = extract_nots_features(users, notifications)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gzI5uoEycoIP","colab_type":"code","colab":{}},"source":["cols_to_drop = ['attributes_notifications_marketing_push', 'attributes_notifications_marketing_email']\n","users = users.drop(columns = cols_to_drop)\n","\n","#users = users.dropna()\n","\n","users = users.reset_index()\n","users.to_csv(project_dir + 'auxiliary_data/users_features.csv', index = False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ge-i1BLwc9ty","colab_type":"code","colab":{}},"source":["#user_temp = users\n","\n","users = users[['plan', 'inbound_transactions', 'outbound_transactions', 'user_settings_crypto_unlocked', 'country', 'NotsPerUser', 'AvgNotsPerMonth', 'AvgPushPerMonth', 'inbound_outbound_ratio']]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0jjKkIskdKif","colab_type":"code","colab":{}},"source":["users['inbound_transactions'] = remove_outliers(users['inbound_transactions'])\n","users['inbound_transactions'] = normalize(users['inbound_transactions'])\n","\n","users['NotsPerUser'] = remove_outliers(users['NotsPerUser'])\n","users['NotsPerUser'] = normalize(users['NotsPerUser'])\n","\n","users['outbound_transactions'] = remove_outliers(users['outbound_transactions'])\n","users['outbound_transactions'] = normalize(users['outbound_transactions'])\n","\n","users['AvgNotsPerMonth'] = standardize(users['AvgNotsPerMonth'])\n","users['AvgPushPerMonth'] = standardize(users['AvgPushPerMonth'])\n","users['inbound_outbound_ratio'] = standardize(users['inbound_outbound_ratio'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EfgXPi8ddiz2","colab_type":"code","colab":{}},"source":["users.to_csv(project_dir + 'auxiliary_data/users_selected_features.csv', index = False)"],"execution_count":0,"outputs":[]}]}