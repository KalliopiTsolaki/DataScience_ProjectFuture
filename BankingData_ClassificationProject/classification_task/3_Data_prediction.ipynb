{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3_Data_prediction.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPowFVcdngWrZRIAGWRQX3x"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"8dWuUKLZAK-P","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import seaborn as sns\n","\n","from datetime import date\n","from sklearn.model_selection import train_test_split, RandomizedSearchCV\n","from sklearn import preprocessing\n","from sklearn.metrics import accuracy_score, f1_score\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import LogisticRegression\n","from imblearn.ensemble import EasyEnsembleClassifier\n","from sklearn.ensemble import VotingClassifier\n","from sklearn.externals import joblib\n","from imblearn.over_sampling import RandomOverSampler\n","from imblearn.under_sampling import RandomUnderSampler\n","from imblearn.under_sampling import TomekLinks\n","from imblearn.under_sampling import NearMiss\n","from imblearn.over_sampling import SMOTE, BorderlineSMOTE\n","from sklearn.model_selection import cross_validate\n","from sklearn import datasets,model_selection,metrics,neural_network,preprocessing\n","from sklearn.utils import shuffle\n","\n","from google.colab import drive\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","import math\n","import re\n","import datetime"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"szymqqDrdNKk","colab_type":"code","colab":{}},"source":["def user_id_to_int(df):\n","  df['user_id'] = df['user_id'].apply(lambda x: int(x.split(\"_\")[1]))\n","  return df\n","\n","\n","def add_inbound_outbound(users,users_trans):\n","  inbound_list = [0] * users.shape[0]\n","  outbound_list = [0] * users.shape[0]\n","  inbound_outbound_ratio_list  = [0] * users.shape[0]\n","\n","  for idx_users_trans, users_trans_row in users_trans.iterrows():\n","    if users_trans_row['direction'] == 'INBOUND':\n","      inbound_list[users_trans_row['user_id']] = inbound_list[users_trans_row['user_id']] + 1\n","    elif users_trans_row['direction'] == 'OUTBOUND':\n","      outbound_list[users_trans_row['user_id']] = outbound_list[users_trans_row['user_id']] + 1\n","\n","  for i in range(len(users)):\n","    inbound_outbound_total = inbound_list[i] + outbound_list[i]\n","    if (inbound_outbound_total == 0):\n","      inbound_outbound_ratio_list[i] = 0\n","    else:  \n","      inbound_outbound_ratio_list[i] = inbound_list[i] / inbound_outbound_total\n","\n","  \n","  inbound_ser = pd.Series(inbound_list)\n","  outbound_ser = pd.Series(outbound_list)\n","  inbound_outbound_ratio_ser = pd.Series(inbound_outbound_ratio_list)\n","  users['inbound_transactions'] = inbound_ser\n","  users['outbound_transactions'] = outbound_ser\n","  users['inbound_outbound_ratio'] = inbound_outbound_ratio_ser\n","  return users\n","\n","\n","def add_completed_to_failed_trans_ratio(users,users_trans):\n","  completed_list = [0] * users.shape[0]\n","  failed_list = [0] * users.shape[0]\n","  completed_failed_ratio_list  = [0] * users.shape[0]\n","\n","  for idx_users_trans, users_trans_row in users_trans.iterrows():\n","    if users_trans_row['transactions_state'] == 'COMPLETED':\n","      completed_list[users_trans_row['user_id']] = completed_list[users_trans_row['user_id']] + 1\n","    elif users_trans_row['transactions_state'] == 'FAILED':\n","      failed_list[users_trans_row['user_id']] = failed_list[users_trans_row['user_id']] + 1\n","\n","  for i in range(len(users)):\n","    completed_failed_total = completed_list[i] + failed_list[i]\n","    if (completed_failed_total == 0):\n","      completed_failed_ratio_list[i] = 0\n","    else:  \n","      completed_failed_ratio_list[i] = completed_list[i] / completed_failed_total\n","\n","  \n","  completed_ser = pd.Series(completed_list)\n","  failed_ser = pd.Series(failed_list)\n","  completed_failed_ratio_ser = pd.Series(completed_failed_ratio_list)\n","  users['completed_transactions'] = completed_ser\n","  users['failed_transactions'] = failed_ser\n","  users['completed_failed_ratio'] = completed_failed_ratio_ser\n","  return users\n","\n","\n","def cardholder_fillna(df):\n","  df['ea_cardholderpresence'] = df['ea_cardholderpresence'].fillna('UNKNOWN')\n","\n","  df['ea_cardholderpresence'] = df['ea_cardholderpresence'].apply(cardholder_pres_fillna)\n","  return df\n","\n","\n","def remove_outliers(series):\n","  x = series\n","  UPPERBOUND, LOWERBOUND = np.percentile(x, [1,99])\n","  y = np.clip(x, UPPERBOUND, LOWERBOUND)\n","  return pd.Series(y)\n","\n","\n","def normalize(series, scaler):\n","  column_as_array = series.to_numpy().reshape(-1,1)\n","  scaled = scaler.transform(column_as_array)\n","  scaled_df = pd.DataFrame(scaled)\n","  return scaled_df[0]\n","\n","\n","def standardize(series, scaler):\n","  column_as_array = series.to_numpy().reshape(-1,1)\n","  scaled = scaler.transform(column_as_array)\n","  scaled_df = pd.DataFrame(scaled)\n","  return scaled_df[0]\n","\n","\n","def cardholder_fillna(df):\n","  df['ea_cardholderpresence'] = df['ea_cardholderpresence'].fillna('UNKNOWN')\n","\n","  df['ea_cardholderpresence'] = df['ea_cardholderpresence'].apply(cardholder_pres_fillna)\n","  return df\n","\n","\n","def cardholder_pres_fillna(presence):\n","  \n","  if presence == 'UNKNOWN':\n","    return 'FALSE'\n","  else:\n","    return presence\n","\n","\n","def add_months_subscribed(users):\n","  now = datetime.datetime.now()\n","  months_subscribed_list = [0] * users.shape[0]\n","\n","  for idx_users, users_row in users.iterrows():\n","    date_split = users_row['created_date'].split(\"-\")\n","    year_created = int(date_split[0])\n","    month_created = int(date_split[1])\n","    if now.year == year_created:\n","      total_months = now.month - month_created\n","    else:\n","      diff = now.year - year_created  \n","      total_months = now.month + ((diff * 12) - month_created)\n","    \n","    months_subscribed_list[idx_users] = total_months\n","\n","  months_subscribed_ser = pd.Series(months_subscribed_list)\n","  users['months_subscribed'] = months_subscribed_ser\n","\n","  return users\n","\n","\n","def mapping_data(users):  \n","  mapping_dict_plan = {'STANDARD': 0, 'SILVER': 1, 'GOLD': 1}\n","  users['plan'] = users['plan'].map(mapping_dict_plan)\n","  return users\n","\n","\n","def extract_trans_features(users, transactions):\n","\n","    user_trans = pd.merge(transactions, users,on='user_id',how='left')\n","\n","    inbound_per_user = pd.DataFrame(transactions[transactions['direction']== 'INBOUND'].groupby(['user_id'])['direction'].size().reset_index(name='inbound_transactions'))\n","    users = pd.merge(inbound_per_user, users, on='user_id', how='outer')\n","    \n","    outbound_per_user = pd.DataFrame(transactions[transactions['direction']== 'OUTBOUND'].groupby(['user_id'])['direction'].size().reset_index(name='outbound_transactions'))\n","    users = pd.merge(outbound_per_user, users, on='user_id', how='outer')\n","\n","\n","\n","    completed_per_user = pd.DataFrame(transactions[transactions['transactions_state']== 'COMPLETED'].groupby(['user_id'])['transactions_state'].size().reset_index(name='completed_transactions'))\n","    users = pd.merge(completed_per_user, users, on='user_id', how='outer')\n","\n","    declined_per_user = pd.DataFrame(transactions[transactions['transactions_state']== 'DECLINED'].groupby(['user_id'])['transactions_state'].size().reset_index(name='declined_transactions'))\n","    users = pd.merge(declined_per_user, users, on='user_id', how='outer')\n","\n","    reverted_per_user = pd.DataFrame(transactions[transactions['transactions_state']== 'REVERTED'].groupby(['user_id'])['transactions_state'].size().reset_index(name='reverted_transactions'))\n","    users = pd.merge(reverted_per_user, users, on='user_id', how='outer')\n","\n","    failed_per_user = pd.DataFrame(transactions[transactions['transactions_state']== 'FAILED'].groupby(['user_id'])['transactions_state'].size().reset_index(name='failed_transactions'))\n","    users = pd.merge(failed_per_user, users, on='user_id', how='outer')\n","\n","    pending_per_user = pd.DataFrame(transactions[transactions['transactions_state']== 'PENDING'].groupby(['user_id'])['transactions_state'].size().reset_index(name='pending_transactions'))\n","    users = pd.merge(pending_per_user, users, on='user_id', how='outer')\n","\n","    cancelled_per_user = pd.DataFrame(transactions[transactions['transactions_state']== 'CANCELLED'].groupby(['user_id'])['transactions_state'].size().reset_index(name='cancelled_transactions'))\n","    users = pd.merge(cancelled_per_user, users, on='user_id', how='outer')\n","\n","    #number of transactions per user\n","    trans_per_user = pd.DataFrame(transactions.groupby(['user_id'])['transactions_state'].size().reset_index(name='TransPerUser'))\n","\n","   \n","    users['inbound_outbound_ratio'] = users['inbound_transactions'] / (users['inbound_transactions'] + users['outbound_transactions'])\n","\n","    users['completed_transactions'] = users['completed_transactions'] / trans_per_user['TransPerUser']\n","    users['declined_transactions'] = users['declined_transactions'] / trans_per_user['TransPerUser']\n","    users['reverted_transactions'] = users['reverted_transactions'] / trans_per_user['TransPerUser']\n","    users['failed_transactions'] = users['failed_transactions'] / trans_per_user['TransPerUser']\n","    users['pending_transactions'] = users['pending_transactions'] / trans_per_user['TransPerUser']\n","    users['cancelled_transactions'] = users['cancelled_transactions'] / trans_per_user['TransPerUser']\n","    \n","    return users.fillna(0)\n","\n","\n","#Giorgos\n","#adjusted net annual income per capita\n","dict2018 = {'GB' : 35837, 'PL':12907,'FR':34837,'IE':43843,'RO':9561,'ES':25686,\n","            'LT':16125,'PT':18799,'MT': 17156 ,'DE':40265,'CH':65578,'CZ':17146,'IT':28806,\n","            'GR':17147,'CY':26328,'LV':13726,'NL' : 44668,'HU':12896,'BE':38814,'SE':46002,'BG':8073,\n","            'DK':51867,'NO':66019,'SI':20691,'AT':42074,'SK':15059,\n","            'HR':12586,'FI':41120,'EE':18993,'LU':60159,'IS' : 58011,'LI': 59872,'AU' : 43346}\n"," \n","#groups =  0-20k,20k-40k,40k-60k,above 60k\n"," \n","def group_countries(adict):\n","    for key,value in adict.items():\n","        if value < 20000:\n","            adict[key] =  1\n","        elif value >=20000 and value <40000:\n","            adict[key] = 2\n","        elif value < 60000 and  value >= 40000:\n","            adict[key] = 3\n","        else:\n","            adict[key] =4\n","    return adict\n","\n","\n","def extract_nots_features(users, notifications):\n","    notifications = extract_date_features(notifications)\n","    notifications = pd.merge(notifications,users,on='user_id',how='left')\n","\n","    #number of notifications per user\n","    nots_per_user = pd.DataFrame(notifications.groupby(['user_id'])['channel'].size().reset_index(name='NotsPerUser'))\n","    users = pd.merge(nots_per_user,users,on='user_id',how='outer')\n","    \n","    #number of emails per user\n","    emails_per_user = pd.DataFrame(notifications[notifications['channel']== 'EMAIL'].groupby(['user_id'])['channel'].size().reset_index(name='EmailsPerUser'))\n","    users = pd.merge(emails_per_user,users,on='user_id',how='outer')\n","\n","    \n","    #number of push per user\n","    push_per_user = pd.DataFrame(notifications[notifications['channel'] == 'PUSH'].groupby('user_id')['channel'].size().reset_index(name='PushPerUser'))\n","    users = pd.merge(push_per_user,users,on='user_id',how='outer')\n","    \n","    #number of SMS per user\n","    sms_per_user = pd.DataFrame(notifications[notifications['channel'] == 'SMS'].groupby('user_id')['channel'].size().reset_index(name='SmsPerUser'))\n","    users = pd.merge(sms_per_user,users,on='user_id',how='outer')\n","   \n","    users['AvgNotsPerMonth'] = users['NotsPerUser'] / users['months_subscribed']\n","    users['AvgEmailsPerMonth'] = users['EmailsPerUser'] / users['months_subscribed']\n","    users['AvgPushPerMonth'] = users['PushPerUser'] / users['months_subscribed']\n","    users['AvgSmsPerMonth'] = users['SmsPerUser'] / users['months_subscribed']\n","    \n","    return users.fillna(0)\n","\n","\n","def clean_string(astring):\n","    #convert to upper and replace empty space\n","    astring = astring.replace(\" \",\"\").upper()\n","    #remove numbers\n","    clean = ''.join([i for i in astring if not i.isdigit()])\n","    #remove special characters\n","    clean = re.sub(r\"^\\W+\", \"\", clean)\n","    #if empty rename to Other\n","    clean.strip()\n","    if len(clean) < 3 or clean == \"\" : clean = 'OTHER'\n","    #check for buchurest and prague\n","    if(clean == 'BUCURESTI' or clean == 'BUCUREȘTI'): clean = 'BUCHAREST'\n","    if(clean == 'PRAHA'): clean = 'PRAGUE'\n","    if(clean == 'WARSZAWA'): clean = 'WARSAW'\n","    if(clean == 'CO.DOUBLIN'): clean = 'DUBLIN'\n","    if(clean == 'LISBOA'): clean = 'LISBON'\n","    if(clean == 'MILANO'): clean = 'MILAN'\n","    if(clean == 'RĪGA'): clean = 'RIGA'\n","    if(clean == 'BRUXELLES'): clean = 'BRUSSELS'\n","    return clean\n","\n","\n","#Map countries to other countries\n","c2c_dict = {'MQ' : 'FR','RE' : 'FR','GP' : 'FR','GI' : 'ES','GG' : 'GB','JE' : 'GB','IM' : 'IE'}            \n","def c2c(country):\n","    if country in c2c_dict.keys():\n","        return c2c_dict.get(country)\n","    return country\n","\n","\n","def extract_date_features(dataframe):\n","    dataframe['created_date'] = [datetime.datetime.strptime(str(date_time_str), '%Y-%m-%d %H:%M:%S.%f') for date_time_str in dataframe['created_date']]\n","    dataframe['part_of_day'] = (dataframe['created_date'].dt.hour %24 + 4) //4\n","    '''dataframe['part_of_day'].replace({1: 'Late Night',\n","                      2: 'Early Morning',\n","                      3: 'Morning',\n","                      4: 'Noon',\n","                      5: 'Evening',\n","                      6: 'Night'},inplace=True)'''\n","    dataframe['part_of_week'] = dataframe['created_date'].dt.weekday\n","    '''dataframe['part_of_week'].replace({0:'Weekday',\n","                                      1:'Weekday',\n","                                      2:'Weekday',\n","                                      3:'Weekday',\n","                                      4:'Weekday',\n","                                      5:'Weekend',\n","                                      6:'Weekend'},inplace=True)'''\n","    dataframe['Half_of_month'] = dataframe['created_date'].dt.day.apply(half_of_month)\n","    dataframe['Month'] = dataframe['created_date'].dt.month\n","    dataframe['Epoch'] = dataframe['created_date'].dt.month.apply(epoch_of_year).map({'Winter':1,'Spring':2,'Summer':3,'Autumn':4})\n","    dataframe['Year'] = dataframe['created_date'].dt.year\n","\n","    return dataframe\n","\n","\n","def epoch_of_year(month):\n","    if month in [12,1,2]:\n","        return 'Winter'\n","    elif month in [3,4,5]:\n","        return 'Spring'\n","    elif month in [6,7,8]:\n","        return 'Summer'\n","    else:\n","        return 'Autumn'\n","\n","\n","def half_of_month(day):\n","    if day <= 15 : return 1\n","    return 2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8dSS_07Muuy4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"a6910359-6b42-4ba3-d0b0-1ccadea4fd4b","executionInfo":{"status":"ok","timestamp":1591648202741,"user_tz":-180,"elapsed":2749,"user":{"displayName":"Popi Ts","photoUrl":"","userId":"05477953627549620209"}}},"source":["drive.mount('/content/drive')\n","project_dir = '/content/drive/My Drive/Colab Notebooks/Data Science-Project Future/pf-ds-thes-team2/'\n","\n","devices_file = project_dir + 'test/devices_test.csv'\n","users_file = project_dir + 'test/users_test.csv'\n","trans_file = project_dir + 'test/transactions_test.csv'\n","notif_file = project_dir + 'test/notifications_test.csv'\n","country_codes_file = project_dir + 'auxiliary_data/country_codes.csv'\n","\n","users_raw = pd.read_csv(users_file)\n","users = users_raw\n","devices = pd.read_csv(devices_file)\n","transactions = pd.read_csv(trans_file)\n","notifications = pd.read_csv(notif_file)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZuSFSwxeuiP7","colab_type":"code","colab":{}},"source":["model = joblib.load(project_dir + 'auxiliary_data/ensemble_classifier.pkl')\n","\n","min_max_scaler_inbound_trans = joblib.load(project_dir + 'auxiliary_data/scalers/MinMax_inbound_transactions.save')\n","min_max_scaler_NotsPerUser = joblib.load(project_dir + 'auxiliary_data/scalers/MinMax_NotsPerUser.save')\n","min_max_scaler_outbound_trans = joblib.load(project_dir + 'auxiliary_data/scalers/MinMax_outbound_transactions.save')\n","stand_scaler_AvgNotsPerMonth = joblib.load(project_dir + 'auxiliary_data/scalers/Stand_AvgNotsPerMonth.save')\n","stand_scaler_AvgPushPerMonth = joblib.load(project_dir + 'auxiliary_data/scalers/Stand_AvgPushPerMonth.save')\n","stand_scaler_inbound_outbound_ratio = joblib.load(project_dir + 'auxiliary_data/scalers/Stand_inbound_outbound_ratio.save')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x3wDpUlfj76g","colab_type":"code","colab":{}},"source":["users = user_id_to_int(users)\n","devices = user_id_to_int(devices)\n","transactions = user_id_to_int(transactions)\n","notifications = user_id_to_int(notifications)\n","transactions = cardholder_fillna(transactions)\n","\n","users_trans = users.merge(transactions, on='user_id', how='left')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uq9c_mIJkWt7","colab_type":"code","colab":{}},"source":["users = add_months_subscribed(users)\n","users = extract_trans_features(users, transactions)\n","\n","cols_to_drop = ['attributes_notifications_marketing_push', 'attributes_notifications_marketing_email']\n","users = users.drop(columns = cols_to_drop)\n","\n","users = users.reset_index(drop=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OzKEShJgl0I7","colab_type":"code","colab":{}},"source":["users['country'] = users['country'].apply(c2c)\n","users['country'] = users['country'].map(group_countries(dict2018))\n","\n","users = extract_nots_features(users, notifications)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QT08jOZSmtPP","colab_type":"code","colab":{}},"source":["users = users[['inbound_transactions', 'outbound_transactions', 'user_settings_crypto_unlocked', 'country', 'NotsPerUser', 'AvgNotsPerMonth', 'AvgPushPerMonth', 'inbound_outbound_ratio']]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eLFpewdMm4xC","colab_type":"code","colab":{}},"source":["users['inbound_transactions'] = remove_outliers(users['inbound_transactions'])\n","users['inbound_transactions'] = normalize(users['inbound_transactions'], min_max_scaler_inbound_trans)\n","\n","users['NotsPerUser'] = remove_outliers(users['NotsPerUser'])\n","users['NotsPerUser'] = normalize(users['NotsPerUser'], min_max_scaler_NotsPerUser)\n","\n","users['outbound_transactions'] = remove_outliers(users['outbound_transactions'])\n","users['outbound_transactions'] = normalize(users['outbound_transactions'], min_max_scaler_outbound_trans)\n","\n","users['AvgNotsPerMonth'] = standardize(users['AvgNotsPerMonth'], stand_scaler_AvgNotsPerMonth)\n","users['AvgPushPerMonth'] = standardize(users['AvgPushPerMonth'], stand_scaler_AvgPushPerMonth)\n","users['inbound_outbound_ratio'] = standardize(users['inbound_outbound_ratio'], stand_scaler_inbound_outbound_ratio)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fq497gf2oMld","colab_type":"code","colab":{}},"source":["X = users"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PQ7z4KY7our1","colab_type":"code","colab":{}},"source":["predictions = model.predict(X)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-swjbkrctCtY","colab_type":"code","colab":{}},"source":["plan_ser = pd.Series(predictions)\n","user_id_ser = users_raw['user_id']\n","\n","frame = { 'user_id': user_id_ser, 'plan': plan_ser } \n","  \n","predictions_df = pd.DataFrame(frame) \n","\n","predictions_df.to_csv(project_dir + 'predictions/test_preds.csv', index = False)"],"execution_count":0,"outputs":[]}]}